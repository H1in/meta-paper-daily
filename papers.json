{"source-free": {}, "object detection": {}, "domain adaptation": {}, "domain generalization": {"PAGE: Domain-Incremental Adaptation with Past-Agnostic Generative Replay for Smart Healthcare": "|**2024-3-12**|**PAGE: Domain-Incremental Adaptation with Past-Agnostic Generative Replay for Smart Healthcare**|Chia-Hao Li et.al|[paper](https://arxiv.org/abs/2403.08197)|-|-|\n", "Unknown Domain Inconsistency Minimization for Domain Generalization": "|**2024-3-12**|**Unknown Domain Inconsistency Minimization for Domain Generalization**|Seungjae Shin et.al|[paper](https://arxiv.org/abs/2403.07329)|[code](https://github.com/SJShin-AI/UDIM)|-|\n", "On the Effectiveness of Large Language Models in Domain-Specific Code Generation": "|**2024-3-12**|**On the Effectiveness of Large Language Models in Domain-Specific Code Generation**|Meng Chen et.al|[paper](https://arxiv.org/abs/2312.01639)|-|<details><summary>detail</summary>Preprint submitted to ACM Transactions on Software Engineering and Methodology</details>|\n", "DiPrompT: Disentangled Prompt Tuning for Multiple Latent Domain Generalization in Federated Learning": "|**2024-3-11**|**DiPrompT: Disentangled Prompt Tuning for Multiple Latent Domain Generalization in Federated Learning**|Sikai Bai et.al|[paper](https://arxiv.org/abs/2403.08506)|-|<details><summary>detail</summary>Journal ref:The IEEE/CVF Conference on Computer Vision and Pattern Recognition 2024</details>|\n", "ReStainGAN: Leveraging IHC to IF Stain Domain Translation for in-silico Data Generation": "|**2024-3-11**|**ReStainGAN: Leveraging IHC to IF Stain Domain Translation for in-silico Data Generation**|Dominik Winter et.al|[paper](https://arxiv.org/abs/2403.06545)|-|-|\n", "AuG-KD: Anchor-Based Mixup Generation for Out-of-Domain Knowledge Distillation": "|**2024-3-10**|**AuG-KD: Anchor-Based Mixup Generation for Out-of-Domain Knowledge Distillation**|Zihao Tang et.al|[paper](https://arxiv.org/abs/2403.07030)|[code](https://github.com/IshiKura-a/AuG-KD)|<details><summary>detail</summary>ICLR 2024</details>|\n", "A Study on Domain Generalization for Failure Detection through Human Reactions in HRI": "|**2024-3-10**|**A Study on Domain Generalization for Failure Detection through Human Reactions in HRI**|Maria Teresa Parreira et.al|[paper](https://arxiv.org/abs/2403.06315)|-|-|\n", "Domain Adversarial Active Learning for Domain Generalization Classification": "|**2024-3-10**|**Domain Adversarial Active Learning for Domain Generalization Classification**|Jianting Chen et.al|[paper](https://arxiv.org/abs/2403.06174)|-|-|\n", "Style Blind Domain Generalized Semantic Segmentation via Covariance Alignment and Semantic Consistence Contrastive Learning": "|**2024-3-10**|**Style Blind Domain Generalized Semantic Segmentation via Covariance Alignment and Semantic Consistence Contrastive Learning**|Woo-Jin Ahn et.al|[paper](https://arxiv.org/abs/2403.06122)|-|<details><summary>detail</summary>CVPR 2024</details>|\n", "M4: Multi-generator, Multi-domain, and Multi-lingual Black-Box Machine-Generated Text Detection": "|**2024-3-9**|**M4: Multi-generator, Multi-domain, and Multi-lingual Black-Box Machine-Generated Text Detection**|Yuxia Wang et.al|[paper](https://arxiv.org/abs/2305.14902)|[code](https://github.com/mbzuai-nlp/M4.)|-|\n", "Leveraging Vision-Language Models for Improving Domain Generalization in Image Classification": "|**2024-3-9**|**Leveraging Vision-Language Models for Improving Domain Generalization in Image Classification**|Sravanti Addepalli et.al|[paper](https://arxiv.org/abs/2310.08255)|[code](http://val.cds.iisc.ac.in/VL2V-ADiP/)|<details><summary>detail</summary>Project page: http://val</details>|\n", "Multisource Semisupervised Adversarial Domain Generalization Network for Cross-Scene Sea-Land Clutter Classification": "|**2024-3-9**|**Multisource Semisupervised Adversarial Domain Generalization Network for Cross-Scene Sea-Land Clutter Classification**|Xiaoxuan Zhang et.al|[paper](https://arxiv.org/abs/2402.06315)|-|-|\n", "A Benchmark of Domain-Adapted Large Language Models for Generating Brief Hospital Course Summaries": "|**2024-3-8**|**A Benchmark of Domain-Adapted Large Language Models for Generating Brief Hospital Course Summaries**|Asad Aali et.al|[paper](https://arxiv.org/abs/2403.05720)|-|-|\n", "ContriMix: Scalable stain color augmentation for domain generalization without domain labels in digital pathology": "|**2024-3-8**|**ContriMix: Scalable stain color augmentation for domain generalization without domain labels in digital pathology**|Tan H. Nguyen et.al|[paper](https://arxiv.org/abs/2306.04527)|[code](https://gitlab.com/huutan86/contrimix)|-|\n", "Multi-Scale and Multi-Layer Contrastive Learning for Domain Generalization": "|**2024-3-8**|**Multi-Scale and Multi-Layer Contrastive Learning for Domain Generalization**|Aristotelis Ballas et.al|[paper](https://arxiv.org/abs/2308.14418)|-|<details><summary>detail</summary>Manuscript accepted in: IEEE Transactions on Artificial Intelligence</details>|\n"}, "vision language": {"AIGCs Confuse AI Too: Investigating and Explaining Synthetic Image-induced Hallucinations in Large Vision-Language Models": "|**2024-3-13**|**AIGCs Confuse AI Too: Investigating and Explaining Synthetic Image-induced Hallucinations in Large Vision-Language Models**|Yifei Gao et.al|[paper](https://arxiv.org/abs/2403.08542)|-|-|\n", "An Empirical Study of Parameter Efficient Fine-tuning on Vision-Language Pre-train Model": "|**2024-3-13**|**An Empirical Study of Parameter Efficient Fine-tuning on Vision-Language Pre-train Model**|Yuxin Tian et.al|[paper](https://arxiv.org/abs/2403.08433)|-|<details><summary>detail</summary>Accepted by ICME2024</details>|\n", "Efficient Prompt Tuning of Large Vision-Language Model for Fine-Grained Ship Classification": "|**2024-3-13**|**Efficient Prompt Tuning of Large Vision-Language Model for Fine-Grained Ship Classification**|Long Lan et.al|[paper](https://arxiv.org/abs/2403.08271)|-|-|\n", "Continuous Object State Recognition for Cooking Robots Using Pre-Trained Vision-Language Models and Black-box Optimization": "|**2024-3-13**|**Continuous Object State Recognition for Cooking Robots Using Pre-Trained Vision-Language Models and Black-box Optimization**|Kento Kawaharazuka et.al|[paper](https://arxiv.org/abs/2403.08239)|[code](https://haraduka.github.io/continuous-state-recognition/)|<details><summary>detail</summary>accepted at IEEE Robotics and Automation Letters (RA-L)</details>|\n", "Interactive Navigation in Environments with Traversable Obstacles Using Large Language and Vision-Language Models": "|**2024-3-12**|**Interactive Navigation in Environments with Traversable Obstacles Using Large Language and Vision-Language Models**|Zhen Zhang et.al|[paper](https://arxiv.org/abs/2310.08873)|-|<details><summary>detail</summary>Accepted by 2024 IEEE International Conference on Robotics and Automation (ICRA)</details>|\n", "ArGue: Attribute-Guided Prompt Tuning for Vision-Language Models": "|**2024-3-12**|**ArGue: Attribute-Guided Prompt Tuning for Vision-Language Models**|Xinyu Tian et.al|[paper](https://arxiv.org/abs/2311.16494)|-|<details><summary>detail</summary>CVPR2024</details>|\n", "TaskCLIP: Extend Large Vision-Language Model for Task Oriented Object Detection": "|**2024-3-12**|**TaskCLIP: Extend Large Vision-Language Model for Task Oriented Object Detection**|Hanning Chen et.al|[paper](https://arxiv.org/abs/2403.08108)|-|-|\n", "Bridging Different Language Models and Generative Vision Models for Text-to-Image Generation": "|**2024-3-12**|**Bridging Different Language Models and Generative Vision Models for Text-to-Image Generation**|Shihao Zhao et.al|[paper](https://arxiv.org/abs/2403.07860)|[code](https://github.com/ShihaoZhaoZSH/LaVi-Bridge.)|-|\n", "MoPE-CLIP: Structured Pruning for Efficient Vision-Language Models with Module-wise Pruning Error Metric": "|**2024-3-12**|**MoPE-CLIP: Structured Pruning for Efficient Vision-Language Models with Module-wise Pruning Error Metric**|Haokun Lin et.al|[paper](https://arxiv.org/abs/2403.07839)|-|-|\n", "Decomposing Disease Descriptions for Enhanced Pathology Detection: A Multi-Aspect Vision-Language Matching Framework": "|**2024-3-12**|**Decomposing Disease Descriptions for Enhanced Pathology Detection: A Multi-Aspect Vision-Language Matching Framework**|Minh Hieu Phan et.al|[paper](https://arxiv.org/abs/2403.07636)|[code](https://github.com/HieuPhan33/MAVL)|<details><summary>detail</summary>CVPR2024</details>|\n", "MoAI: Mixture of All Intelligence for Large Language and Vision Models": "|**2024-3-12**|**MoAI: Mixture of All Intelligence for Large Language and Vision Models**|Byung-Kwan Lee et.al|[paper](https://arxiv.org/abs/2403.07508)|[code](https://github.com/ByungKwanLee/MoAI)|<details><summary>detail</summary>Code available: https://github</details>|\n", "NavCoT: Boosting LLM-Based Vision-and-Language Navigation via Learning Disentangled Reasoning": "|**2024-3-12**|**NavCoT: Boosting LLM-Based Vision-and-Language Navigation via Learning Disentangled Reasoning**|Bingqian Lin et.al|[paper](https://arxiv.org/abs/2403.07376)|[code](https://github.com/expectorlin/NavCoT.)|-|\n", "KEBench: A Benchmark on Knowledge Editing for Large Vision-Language Models": "|**2024-3-12**|**KEBench: A Benchmark on Knowledge Editing for Large Vision-Language Models**|Han Huang et.al|[paper](https://arxiv.org/abs/2403.07350)|-|-|\n", "Vision-Language Models Learn Super Images for Efficient Partially Relevant Video Retrieval": "|**2024-3-11**|**Vision-Language Models Learn Super Images for Efficient Partially Relevant Video Retrieval**|Taichi Nishimura et.al|[paper](https://arxiv.org/abs/2312.00414)|-|-|\n", "Towards Zero-shot Human-Object Interaction Detection via Vision-Language Integration": "|**2024-3-11**|**Towards Zero-shot Human-Object Interaction Detection via Vision-Language Integration**|Weiying Xue et.al|[paper](https://arxiv.org/abs/2403.07246)|-|-|\n"}}